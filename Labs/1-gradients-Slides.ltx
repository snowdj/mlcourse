\title{Recitation 1}
\subtitle{Gradients and Directional Derivatives}
\begin{document}
\begin{frame} 
  \titlepage 
\end{frame}
\section{Administrative}
\begin{frame}
  \frametitle{Administrative Info}
  \begin{itemize}
  \item Make sure you are signed up for the Spring 2019 instance of
    the class on Piazza.  The link is on the class webpage (link is fixed now).
  \item All students must submit the first homework on
    Gradescope using an access code available on Piazza.
  \item Students on the waiting list expecting to enroll must also
    submit the first homework on Gradescope using the access code on Piazza.
  \end{itemize}
\end{frame}
\section{Recitation 1}
\subsection{Initial Question}
\begin{frame}[fragile]
  \frametitle{Intro Question}
  \begin{block}{Question}
    We are given the data set $(x_1,y_1),\ldots,(x_n,y_n)$ where
    $x_i\in\RR$ and $y_i\in\RR$.  We want to fit a linear function to
    this data by performing empirical risk minimization.  More
    precisely, we are using the hypothesis space $\FF=\{h_\theta(x)=\theta_1x+\theta_2\mid
    \theta\in\RR^2\}$ and the loss function $\ell(a,y)=(a-y)^2$.  Given an
    initial guess $\tilde{\theta}$ for the empirical risk minimizing
    parameter vector, how could we improve our guess?
  \end{block}
\begin{center}
\includegraphics[width=0.4\textwidth,height=0.4\textheight]{1-gradients/Data.pdf}
\end{center}
\end{frame}
\begin{frame}
  \frametitle{Intro Solution}
  \begin{block}{Solution}
    \begin{itemize}
    \item The empirical risk is given by
      $$\begin{Array}{rcl}
      \hspace{-0.5cm}J(\theta) & := & \hat{R}_n(h_\theta) = \frac{1}{n}\sum_{i=1}^n \ell(\theta_1x_i+\theta_2,y_i) =
      \frac{1}{n}\sum_{i=1}^n (\theta_1x_i+\theta_2-y_i)^2\\
      & = & \frac{1}{n}\|X\theta-y\|_2^2,
      \end{Array}$$
      where $X\in\RR^{n\times 2}$ is the matrix whose $i$th row is
      given by $(x_i,1)$.
    \item Can improve a non-optimal guess $\tilde{\theta}$ by taking a
      small step in the direction of the negative gradient $-\nabla J(\theta)$.
    \end{itemize}
  \end{block}  
\end{frame}
\begin{frame}
  \frametitle{Negative Gradient Steps}
  \begin{center}
    \includegraphics[width=0.4\textwidth]{1-gradients/contour0.pdf}
    \includegraphics[width=0.4\textwidth]{1-gradients/Data0.pdf}
  \end{center}
\end{frame}
\begin{frame}
  \frametitle{Negative Gradient Steps}
  \begin{center}
    \includegraphics[width=0.4\textwidth]{1-gradients/contour1.pdf}
    \includegraphics[width=0.4\textwidth]{1-gradients/Data1.pdf}
  \end{center}
\end{frame}
\begin{frame}
  \frametitle{Negative Gradient Steps}
  \begin{center}
    \includegraphics[width=0.4\textwidth]{1-gradients/contour2.pdf}
    \includegraphics[width=0.4\textwidth]{1-gradients/Data2.pdf}
  \end{center}
\end{frame}
\begin{frame}
  \frametitle{Negative Gradient Steps}
  \begin{center}
    \includegraphics[width=0.4\textwidth]{1-gradients/contour3.pdf}
    \includegraphics[width=0.4\textwidth]{1-gradients/Data3.pdf}
  \end{center}
\end{frame}
\begin{frame}
  \frametitle{Negative Gradient Steps}
  \begin{center}
    \includegraphics[width=0.4\textwidth]{1-gradients/contour4.pdf}
    \includegraphics[width=0.4\textwidth]{1-gradients/Data4.pdf}
  \end{center}
\end{frame}
\begin{frame}
  \frametitle{Negative Gradient Steps}
  \begin{center}
    \includegraphics[width=0.4\textwidth]{1-gradients/contour5.pdf}
    \includegraphics[width=0.4\textwidth]{1-gradients/Data5.pdf}
  \end{center}
\end{frame}
\begin{frame}
  \frametitle{Negative Gradient Steps}
  \begin{center}
    \includegraphics[width=0.4\textwidth]{1-gradients/contour10.pdf}
    \includegraphics[width=0.4\textwidth]{1-gradients/Data10.pdf}
  \end{center}
\end{frame}
\begin{frame}
  \frametitle{Negative Gradient Steps}
  \begin{center}
    \includegraphics[width=0.4\textwidth]{1-gradients/contour15.pdf}
    \includegraphics[width=0.4\textwidth]{1-gradients/Data15.pdf}
  \end{center}
\end{frame}
\begin{frame}
  \frametitle{Negative Gradient Steps}
  \begin{center}
    \includegraphics[width=0.4\textwidth]{1-gradients/contour20.pdf}
    \includegraphics[width=0.4\textwidth]{1-gradients/Data20.pdf}
  \end{center}
\end{frame}
\begin{frame}
  \frametitle{Negative Gradient Steps}
  \begin{center}
    \includegraphics[width=0.4\textwidth]{1-gradients/contour25.pdf}
    \includegraphics[width=0.4\textwidth]{1-gradients/Data25.pdf}
  \end{center}
\end{frame}
\begin{frame}
  \frametitle{Negative Gradient Steps}
  \begin{center}
    \includegraphics[width=0.4\textwidth]{1-gradients/contour50.pdf}
    \includegraphics[width=0.4\textwidth]{1-gradients/Data50.pdf}
  \end{center}
\end{frame}
\subsection{Single Variable Calculus}
\begin{frame}
  \frametitle{Single Variable Differentiation}
  \begin{itemize}
  \item Calculus lets us turn non-linear problems into linear algebra.
  \item For $f:\RR\to\RR$ differentiable, the derivative is given by
    $$f'(x) = \lim_{h\to 0} \frac{f(x+h)-f(x)}{h}.$$
  \item Can also be written as
    $$f(x+h) = f(x) + hf'(x) + o(h)\quad\text{as $h\to 0$,}$$
    where $o(h)$ denotes a function $g(h)$ with $g(h)/h\to 0$ as
    $h\to0$.
  \item Points with $f'(x) = 0$ are called \textit{critical points}.
  \end{itemize}
\end{frame}
\begin{frame}[fragile]
  \frametitle{1D Linear Approximation By Derivative}
\begin{center}
\includegraphics[width=\textwidth,height=0.8\textheight]{1-gradients/Taylor1d.pdf}
\end{center}
\end{frame}

\subsection{Multivariable Calculus}
\begin{frame}
  \frametitle{Multivariable Differentiation}
  \begin{itemize}
  \item Consider now a function $f:\RR^n\to\RR$ with inputs of the
    form $x=(x_1,\ldots,x_n)^T\in\RR^n$.
  \item Unlike the 1-dimensional case, we cannot assign a single
    number to the slope at a point since there are many directions we can move in.
  \end{itemize}
\end{frame}
\begin{frame}[fragile]
  \frametitle{Multiple Possible Directions for $f:\RR^2\to\RR$}
\begin{center}
\includegraphics[width=\textwidth,height=0.8\textheight]{1-gradients/Directions.pdf}
\end{center}
\end{frame}
\begin{frame}
  \frametitle{Multivariable Differentiation}
  \begin{enumerate}
  \item We will look at two (related) methods for understanding
    multivariable differentiation:
    \begin{enumerate}
    \item Directional Derivatives: Derivative computed along a single
      direction
    \item Gradient: Gives multidimensional linear approximation and
      the steepest ascent direction
    \end{enumerate}
  \end{enumerate}
\end{frame}
\begin{frame}
  \frametitle{Directional Derivative}
  \begin{block}{Definition}
    Let $f:\RR^n\to\RR$.  The directional derivative $f'(x;u)$ of $f$ at $x\in\RR^n$ in
    the direction $u\in\RR^n$ is given by
    $$f'(x;u) = \lim_{h\to0}\frac{f(x+hu)-f(x)}{h}.$$
  \end{block}
  \begin{itemize}
  \item By fixing a direction $u$ we turned our multidimensional
    problem into a 1-dimensional problem.
  \item Similar to 1-d we have
    $$f(x+hu) = f(x) + hf'(x;u) + o(h).$$
  \item We say that $u$ is a \textit{descent direction} of $f$ at $x$
    if $f'(x;u)<0$.
  \item Taking a small enough step in a descent
    direction causes the function value decreases.
  \end{itemize}
\end{frame}
\begin{frame}[fragile]
  \frametitle{Directional Derivative as a Slope of a Slice}
\begin{center}
\includegraphics[width=0.7\textwidth,height=0.8\textheight]{1-gradients/Slice.pdf}
\end{center}
\end{frame}

\begin{frame}
  \frametitle{Partial Derivative}
  \begin{itemize}
  \item Let $e_i=(\overbrace{0,0,\ldots,0}^{i-1},1,0,\ldots,0)$ denote the $i$th
    standard basis vector.
  \item The $i$th \textit{partial derivative} is defined to be the
    directional derivative along $e_i$.
  \item It can be written many ways:
    $$f'(x;e_i) = \frac{\partial}{\partial x_i}f(x) =
    \partial_{x_i}f(x) = \partial_if(x).$$
  \item What is the intuitive meaning of $\partial_{x_i}f(x)$?  For
    example, what does a large value of $\partial_{x_3}f(x)$ imply?
  \end{itemize}
\end{frame}
\begin{frame}
  \frametitle{Differentiability and Gradients}
  \begin{itemize}
  \item We say a function $f:\RR^n\to\RR$ is \textit{differentiable}
    at $x\in\RR^n$ if
    $$\lim_{v\to0}\frac{f(x+v)-f(x) -g^Tv}{\|v\|_2} = 0,$$
    for some $g\in\RR^n$.
  \item If it exists, this $g$ is unique and is called the \textit{gradient} of $f$ at
    $x$ with notation
    $$g = \nabla f(x).$$
  \item It can be shown that
    $$\nabla f(x) =
    \pMattt{\partial_{x_1}f(x)}{\vdots}{\partial_{x_n}f(x)}.$$
  \end{itemize}
\end{frame}
\begin{frame}
  \frametitle{Useful Convention}
  \begin{itemize}
  \item Consider $f:\RR^{p+q}\to\RR$.
  \item Split the input $x\in\RR^{p+q}$ into parts $w\in\RR^p$ and $z\in\RR^q$
    so that~$x=(w,z)$.
  \item Define the partial gradients
    $$\hspace{-.5cm}\nabla_w f(w,z) :=
    \pMattt{\partial_{w_1}f(w,z)}{\vdots}{\partial_{w_p}f(w,z)}
    \quad\text{and}\quad
    \nabla_z f(w,z) :=
    \pMattt{\partial_{z_1}f(w,z)}{\vdots}{\partial_{z_q}f(w,z)}.
    $$
  \end{itemize}
\end{frame}
\begin{frame}
  \frametitle{Linear Approximation and Tangent Plane}
  \begin{itemize}
  \item Gradient gives us a linear approximation of $f$ near the point
    $x$:
    $$f(x+v)\approx f(x)+\nabla f(x)^Tv.$$
  \item Analogous to the 1-d case we can express differentiability as
    $$f(x+v) = f(x) + \nabla f(x)^Tv + o(\|v\|_2).$$
  \item The gradient approximation can be seen as a tangent plane given by
    $$P = \{(x+v,f(x)+\nabla f(x)^Tv)\mid v\in\RR^n\}\subseteq
    \RR^{n+1}.$$
  \item Methods like gradient descent approximate a function locally
    by its tangent plane, and then take a step accordingly.
  \end{itemize}
\end{frame}
\begin{frame}[fragile]
  \frametitle{Tangent Plane for $f:\RR^2\to\RR$}
\begin{center}
  \includegraphics[width=\textwidth,height=0.8\textheight]{1-gradients/Tangent.pdf}
\end{center}
\end{frame}
\begin{frame}
  \frametitle{Directional Derivatives from Gradients}
  \begin{itemize}
  \item If $f$ is differentiable we obtain a formula for any
    directional derivative in terms of the gradient
    $$f'(x;u) = \nabla f(x)^Tu.$$
  \item This implies that a direction is a descent direction if and only if
    it makes an acute angle with the negative gradient.
  \item If $\nabla f(x)\neq 0$ applying Cauchy-Schwarz gives
    $$\argmax_{\|u\|_2=1} f'(x;u) = \frac{\nabla f(x)}{\|\nabla f(x)\|_2}
    \quad\text{and}\quad
    \argmin_{\|u\|_2=1} f'(x;u) = -\frac{\nabla f(x)}{\|\nabla
      f(x)\|_2}.$$
  \item The gradient points in the direction of
    steepest ascent.
  \item The negative gradient points in the direction of
    steepest descent.
  \end{itemize}
\end{frame}
\begin{frame}
  \frametitle{Critical Points}
  \begin{itemize}
  \item Analogous to 1-d, if $f:\RR^n\to\RR$ is differentiable and $x$
    is a local extremum then we must have $\nabla f(x)=0$.
  \item Points with $\nabla f(x)=0$ are called \textit{critical
    points}.
  \item Later in the course we will see that for a convex differentiable function,
    $x$ is a critical point if and only if it is a global minimizer.
  \end{itemize}
\end{frame}
\begin{frame}[fragile]
  \frametitle{Critical Points of $f:\RR^2\to\RR$}
\begin{center}
\includegraphics[width=\textwidth,height=0.8\textheight]{1-gradients/Saddle.pdf}
\end{center}
\end{frame}
\begin{frame}
  \frametitle{Recap}
  \begin{itemize}
  \item To find a good decision function we will minimize the
    empirical loss on the training data.
  \item Having fixed a hypothesis space parameterized by $\theta$,
    finding a good decision function means finding a good $\theta$.
  \item Given a current guess for $\theta$, we will use the gradient
    of the empirical loss (w.r.t.~$\theta$)
    to get a local linear approximation.
  \item If the gradient is non-zero, taking a small step in the direction of the negative
    gradient is guaranteed to decrease the empirical loss.
  \item This motivates the minimization algorithm called gradient descent.
  \end{itemize}
\end{frame}
\subsection{Computing Gradients}
\begin{frame}[fragile]
  \frametitle{Computing Gradients}
  \begin{block}{Question}
    For questions 1 and 2, compute the gradient of the given function.
    \begin{enumerate}
    \item $J:\RR^3\to\RR$ is given by
      $$J(\theta_1,\theta_2,\theta_3) = \log(1+e^{\theta_1+2\theta_2+3\theta_3}).$$
    \item $J:\RR^n\to\RR$ is given by
      $$J(\theta) = \|X\theta-y\|_2^2 = (X\theta-y)^T(X\theta-y) = \theta^TX^TX\theta - 2y^TX\theta+y^Ty,$$
      for some $X\in\RR^{m\times n}$ and $y\in\RR^m$.
    \item Assume $X$ in the previous question has full column rank.
      What is the critical point of $J$?
    \end{enumerate}
  \end{block}
\end{frame}
\begin{frame}
  \frametitle{$J(\theta_1,\theta_2,\theta_3)=\log(1+e^{\theta_1+2\theta_2+3\theta_3})$ Solution 1}
  We can compute the partial derivatives directly:
  $$\begin{Array}{rcl}
    \partial_{\theta_1} J(\theta_1,\theta_2,\theta_3) &=&\frac{e^{\theta_1+2\theta_2+3\theta_3}}{1+e^{\theta_1+2\theta_2+3\theta_3}}\\
    \partial_{\theta_2} J(\theta_1,\theta_2,\theta_3) &=&\frac{2e^{\theta_1+2\theta_2+3\theta_3}}{1+e^{\theta_1+2\theta_2+3\theta_3}}\\
    \partial_{\theta_3} J(\theta_1,\theta_2,\theta_3) &=&
    \frac{3e^{\theta_1+2\theta_2+3\theta_3}}{1+e^{\theta_1+2\theta_2+3\theta_3}}
    \end{Array}$$
  and obtain
  $$\nabla J(\theta_1,\theta_2,\theta_3) =
  \PMattt{\frac{e^{\theta_1+2\theta_2+3\theta_3}}{1+e^{\theta_1+2\theta_2+3\theta_3}}}
         {\frac{2e^{\theta_1+2\theta_2+3\theta_3}}{1+e^{\theta_1+2\theta_2+3\theta_3}}}
         {\frac{3e^{\theta_1+2\theta_2+3\theta_3}}{1+e^{\theta_1+2\theta_2+3\theta_3}}}.$$         
\end{frame}
\begin{frame}
  \frametitle{$J(\theta_1,\theta_2,\theta_3)=\log(1+e^{\theta_1+2\theta_2+3\theta_3})$ Solution 2}
  \begin{itemize}
  \item Spot the linear algebra!
  \item Let $w=(1,2,3)^T$.
  \item Write $J(\theta) = \log(1+e^{w^T\theta})$.
  \item Apply a version of the chain rule (twice):
    $$\nabla J(\theta) = \frac{e^{w^T\theta}}{1+e^{w^T\theta}}w.$$
  \end{itemize}
  \begin{theorem}[Chain Rule]
    If $g:\RR\to\RR$ and $h:\RR^n\to\RR$ are differentiable then
    $$\nabla (g\circ h)(x) = g'(h(x))\nabla h(x).$$
  \end{theorem}
\end{frame}
\begin{frame}
  \frametitle{$J(\theta) = \|X\theta-y\|_2^2$ Solution}
  \begin{itemize}
  \item We could use techniques similar to the previous problem, but
    instead we show a different method using directional derivatives.
  \item For arbitrary $t\in\RR$ and $\theta,v\in\RR^n$ we have
    $$\hspace{-.5cm}\begin{array}{rcl}
    \multicolumn{3}{l}{J(\theta+tv)}\\
    & = & (\theta+tv)^TX^TX(\theta+tv) - 2y^TX(\theta+tv)+y^Ty \\
    & = & \underline{\theta^TX^TX\theta} + t^2v^TX^TXv + 2t\theta^TX^TXv-\underline{2y^TX\theta}-2ty^TXv+\underline{y^Ty}\\
    & = & \underline{J(\theta)} + t(2\theta^TX^TX - 2y^TX)v + t^2v^TX^TXv.
  \end{array}$$
  \item This gives
    $$J'(\theta;v)=\lim_{t\to0}\frac{J(\theta+tv)-J(\theta)}{t}
    = (2\theta^TX^TX - 2y^TX)v = \nabla J(\theta)^Tv$$
  \item Thus $\nabla J(\theta) = 2(X^TX\theta-X^Ty) = 2X^T(X\theta-y)$.
  \item Data science interpretation of $\nabla J(\theta)$ (assuming
    columns of $X$ are centered)?
  \end{itemize}
\end{frame}
\begin{frame}
  \frametitle{Critical Points of $J(\theta)=\|X\theta-y\|_2^2$}
  \begin{itemize}
  \item Need $\nabla J(\theta) = 2X^TX\theta-2X^Ty=0$.
  \item Since $X$ is assumed to have full column rank, we see that
    $X^TX$ is invertible.
  \item Thus we have $\theta=(X^TX)^{-1}X^Ty$.
  \item As we will see later, this function is strictly convex (Hessian
    $\nabla^2J(\theta) = 2X^TX$ is positive definite).
  \item Thus we have found the unique minimizer (least squares solution).
  \end{itemize}
\end{frame}
\begin{frame}
  \frametitle{Technical Aside: Differentiability}
  \begin{itemize}
  \item When computing the gradients above we assumed the functions were
    differentiable.
  \item Can use the following theorem to be completely rigorous.
  \end{itemize}
  \begin{theorem}
    Let $f:\RR^n\to\RR$ and suppose $\partial_if:\RR^n\to\RR$ is
    continuous for $i=1,\ldots,n$. Then $f$ is differentiable.
  \end{theorem}
\end{frame}
\end{document}
